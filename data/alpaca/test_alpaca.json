[
  {
    "instruction": "Remove files from tar archive\n\nI have a large file \nfoo.tar.xz\n that contains a lot (say 200000) of files. I figured out that this archive contains some (around 5000) files I don't want. I don't have sufficient disk space to decompress the whole thing onto my disk; additionally, I fear attributes / rights might get lost if I do so. I have enough space to host two copies of the \ncompressed\n archive though. Is there a tool to remove some of the files from the archive (specified with a regex on the filename) on-the-fly, i.e. without unpacking the archive into individual files?",
    "input": "",
    "output": "GNU tar has a \n--delete\n option that works with archives too nowadays.\n\n\nUse it like this, for example:\n\n\n\n```bash\ntar -vf yourArchive.tar --delete your/path/to/delete\n```\n\n\n\nBeware:\n It will most likely \nnot\n work on any kind of magnetic tape medium. But \ntar\n has no problems working in a pipe, so you can just use a temporary tar file and overwrite the tape with that afterwards. It also won't work on compressed files, so you would need to uncompress the file.\n\n\nAlso, the operation will be rather slow in any case, due to the (by design) packed linear nature of tar archives."
  },
  {
    "instruction": "Display only relevant hunks of a diff/patch based on a regexp\n\ngit log -G<regex> -p\n is a wonderful tool to search a codebase's history for changes that match the specified pattern. However, it can be overwhelming to locate the relevant hunk in the diff/patch output in a sea of mostly irrelevant hunks.\n\n\nIt’s of course possible to search the output of \ngit log\n for the original string/regex, but that does little to reduce the visual noise and distraction of many unrelated changes.\n\n\nReading up on \ngit log\n, I see there's the \n--pickaxe-all\n, which is the exact opposite of what I want: it broadens the output (to the entire changeset), whereas I want to limit it (to the specific hunk).\n\n\nEssentially, I’m looking for a way to \"intelligently\" parse the diff/patch into individual hunks and then execute a search against each hunk (targeting just the changed lines), discard the hunks that don’t match, and output the ones that do.\n\n\nDoes a tool such as I describe exist? Is there a better approach to get the matched/affected hunks?\n\n\nSome initial research I've done...\n\n\n\n\nIf it were possible to \ngrep\n the diff/patch output and make the context option values dynamic—say, via regexps instead of line counts—that might suffice. But \ngrep\n isn't exactly built that way (nor am I necessarily requesting that feature).\n\n\nI found the \npatchutils\n suite, which initially sounded like it might suit my needs. But after reading its \nman\n pages, the tools doesn't appear to handle matching hunks based on regexps. (They can accept a list of hunks, though...)\n\n\nI finally came across \nsplitpatch.rb\n, which seems to handle the parsing of the patch well, but it would need to be significantly augmented to handle reading patches via \nstdin\n, matching desired hunks, and then outputting the hunks.",
    "input": "",
    "output": "here \nhttps://stackoverflow.com/a/35434714/5305907\n is described a way to do what you are looking for. effectively:\n\n\ngit diff -U1 | grepdiff 'console' --output-matching=hunk\n\n\nIt shows only the hunks that match with the given string \"console\"."
  },
  {
    "instruction": "Why use superflous dash (-) to pass option flags to tar?\n\nTo create a tar file for a directory, the \ntar\n command with \ncompress\n, \nverbose\n and \nfile\n options can be typed thus:\n\n\n\n```bash\n$ tar -cvf my.tar my_directory/\n```\n\n\n\nBut it also works to do it this way:\n\n\n\n```bash\n$ tar cvf my.tar my_directory/\n```\n\n\n\nThat is, without the dash (-) preceding the options. Why would you ever pass a dash (-) to the option list?",
    "input": "",
    "output": "There are several different patterns for options that have been used historically in UNIX applications.  Several old ones, like \ntar\n, use a positional scheme:\n\n\n\n> command options arguments\n\n\n\nas for example tar uses\n\n\n\n> tar *something*f \"file operated on\" *\"paths of files to manipulate\"*\n\n\n\nIn a first attempt to avoid the confusion, \ntar\n and a few other programs with the old flags-arguments style allowed delimiting the flags with dashes, but most of us old guys simply ignored that.\n\n\nSome other commands have a more complicated command line syntax, like \ndd(1)\n which uses flags, equal signs, pathnames, arguments and a partridge in a pear tree, all with wild abandon.\n\n\nIn BSD and later versions of unix, this had more or less converged to single-character flags marked with '-', but this began to present a couple of problems:\n\n\n\n\nthe flags could be hard to remember\n\n\nsometimes you actually wanted to use a name with '-'\n\n\nand especially with GNU tools, there began to be limitations imposed by the number of possible flags.  So GNU tools added GNU long options like \n--output\n.\n\n\n\n\nThen Sun decided that the extra '-' was redundant and started using long-style flags with single '-'s.\n\n\nAnd that's how it came to be the mess it is now."
  },
  {
    "instruction": "Why is less being run unnecessarily by git?\n\nWhen I run \ngit branch\n (from bash or csh), it automagically pipes the output through \nless\n. However, with only a few branches in the repository this is beyond unnecessary, it is annoying, as the branch listing disappears once I quit less. \n\n\nChecking \n~/.gitconfig\n file and the local \n.git/config\n files finds nothing about a pager or any thing else that would cause this. Otherwise, nothing I've found in web searches has been helpful or promising.\n\n\nWhy is this happening, and what (if anything) can I do to make \nless\n run when needed (e.g. when doing a \ngit log\n when there's a lot of history) but not otherwise (like a \ngit branch\n with only 2 or 3 branches)?",
    "input": "",
    "output": "You can set the following:\n\n\n\n```bash\ngit config --global core.pager 'less -FRX'\n```\n\n\n\nThis will ensure that \nless\n will\n\n\n\n\nExit if the entire file can be displayed on the first screen (\nF\n)\n\n\nOutput the raw control characters for terminal formatting (\nR\n)\n\n\nChop long lines (\nS\n)\n\n\nDon't send the init/de-init strings to the terminal - avoids clearing the screen on exit (\nX\n)\n\n\n\n\nEdit: Removed the \nS\n option based on Peter A. Scheider's comment"
  },
  {
    "instruction": "How to keep track of changes in /etc/\n\nI would like to keep track of changes in /etc/\n\n\nBasically I'd like to know if a file was changed, by \nyum update\n or by a user and roll it back if I don't like the chage.\nI thought of using a VCS like git, LVM or btrfs snapshots or a backup program for this. \n\n\nWhat would you recommend?",
    "input": "",
    "output": "It sounds like you want \netckeeper\n from Joey Hess of Debian, which manages files under \n/etc\n using version control.  It supports git, mercurial, darcs and bazaar.\n\n\n\n> git is the VCS best supported by etckeeper and the VCS users are most likely to know.  It's possible that your distribution has chosen to modify etckeeper so its default VCS is not git. You should only be using etckeeper with a VCS other than git if you're in love with the other VCS."
  },
  {
    "instruction": "How to remove a single line from history?\n\nI'm working in Mac OSX, so I guess I'm using bash...?\n\n\nSometimes I enter something that I don't want to be remembered in the history. How do I remove it?",
    "input": "",
    "output": "Preventative measures\n\n\nIf you want to run a command without saving it in history, prepend it with an extra space\n\n\n\n```bash\nprompt$ echo saved\nprompt$  echo not saved \\\n> #     ^ extra space\n```\n\n\n\nFor this to work you need either \nignorespace\n or \nignoreboth\n in \nHISTCONTROL\n.  For example, run\n\n\n\n```bash\nHISTCONTROL=ignorespace\n```\n\n\n\nTo make this setting persistent, put it in your \n.bashrc\n.\n\n\nPost-mortem clean-up\n\n\nIf you've already run the command, and want to remove it from history, first use\n\n\n\n```bash\nhistory\n```\n\n\n\nto display the list of commands in your history.  Find the number next to the one you want to delete (e.g. 1234) and run \n\n\n\n```bash\nhistory -d 1234\n```\n\n\n\nAdditionally, if the line you want to delete has already been written to your $HISTFILE (which typically happens when you end a session by default), you will need to write back to $HISTFILE, or the line will reappear when you open a new session:\n\n\n\n```bash\nhistory -w\n```"
  },
  {
    "instruction": "Is there any way to execute commands from history?\n\nFor example:\n\n\n\n```bash\n[root@ip-10-0-7-125 ~]# history | grep free\n  594  free -m\n  634  free -m | xargs | awk '{print \"free/total memory\" $17 \" / \" $ 8}'\n  635  free -m\n  636  free -m | xargs | awk '{print \"free/total memory\" $9 \" / \" $ 10}'\n  736  df -h | xargs |  awk '{print \"free/total disk: \" $11 \" / \" $9}'\n  740  df -h | xargs |  awk '{print \"free/total disk: \" $11 \" / \" $8}'\n  741  free -m | xargs | awk '{print \"free/total memory: \" $17 \" / \" $8 \" MB\"}'\n```\n\n\n\nI'm just wondering if there any way to execute the 636 command without typing it again, just type something plus the number, like history 636 or something.",
    "input": "",
    "output": "In bash, just \n!636\n will be ok."
  },
  {
    "instruction": "tr complains of “Illegal byte sequence”\n\nI'm brand new to UNIX and I am using Kirk McElhearn's \"The Mac OS X Command Line\" to teach myself some commands. \n\n\nI am attempting to use \ntr\n and \ngrep\n so that I can search for text strings in a regular MS-Office Word Document. \n\n\n\n```bash\n$ tr '\\r' '\\n' < target-file | grep search-string\n```\n\n\n\nBut all it returns is:\n\n\n\n```bash\nIllegal byte sequence.\n```\n\n\n\n\n\n\n```bash\nrobomechanoid:Position-Paper-Final-Draft robertjralph$ tr '\\r' '\\n' < Position-Paper-Final-Version.docx | grep DeCSS\ntr: Illegal byte sequence\nrobomechanoid:Position-Paper-Final-Draft robertjralph$\n```\n\n\n\nI've actually run the same line on a script that I created in \nvi\n and it does the search correctly.",
    "input": "",
    "output": "grep\n is a text processing tool. It expects their input to be \ntext files\n. It seems that the same goes for \ntr\n on macOS (even though \ntr\n is supposed to support binary files).\n\n\nComputers store data as sequences of \nbytes\n. A text is a sequence of characters. There are several ways to encode characters as bytes, called \ncharacter encodings\n. The de facto standard character encoding in most of the world, especially on OSX, is \nUTF-8\n, which is an encoding for the \nUnicode\n character set. There are only 256 possible bytes, but over a million possible Unicode characters, so most characters are encoded as multiple bytes. UTF-8 is a variable-length encoding: depending on the character, it can take from one to four bytes to encode a character. Some sequences of bytes do not represent any character in UTF-8. Therefore, there are sequences of bytes which are not valid UTF-8 text files.\n\n\ntr\n is complaining because it encountered such a byte sequence. It expects to see a text file encoded in UTF-8, but it sees binary data which is not valid UTF-8.\n\n\nA Microsoft Word document is not a text file: it's a word processing document. Word processing document formats encode not only text, but also formatting, embedded images, etc. The Word format, like most word processing formats, is not a text file.\n\n\nYou can instruct text processing tools to operate on bytes by changing the \nlocale\n. Specifically, select the “C” locale, which basically means means “nothing fancy”. On the command line, you can choose locale settings with \nenvironment variables\n.\n\n\n\n```bash\nexport LC_CTYPE=C\ntr '\\r' '\\n' < target-file | grep search-string\n```\n\n\n\nThis will not emit any error, but it won't do anything useful either since \ntarget-file\n is still a binary file which is unlikely to contain most search strings that you'll specify.\n\n\nIncidentally, \ntr '\\r' '\\n'\n is not a very useful command unless you have text files left over from Mac OS 9 or older. \n\\r\n (carriage return) was the newline separator in Mac OS before Mac OS X. Since OSX, the newline separator is \n\\n\n (line feed, the unix standard) and text files do not contain carriage returns. Windows uses the two-character sequence CR-LF to represent line breaks; \ntr -d '\\r'\n would convert a Windows text file into a Unix/Linux/OSX text file.\n\n\nSo how can you search in a Word document from the command line? A \n.docx\n Word document is actually a \nzip archive\n containing several files, the main ones being in \nXML\n. \n\n\n\n```bash\nunzip -l Position-Paper-Final-Version.docx\n```\n\n\n\nMac OS X includes the \nzipgrep\n utility to search inside zip files.\n\n\n\n```bash\nzipgrep DeCSS Position-Paper-Final-Version.docx\n```\n\n\n\nThe result is not going to be very readable because XML files in the docx format mostly consist of one huge line. If you want to search inside the main body text of the document, extract the file \nword/document.xml\n from the archive. Note that in addition to the document text, this file contains XML markup which represents the structure of the document. You can massage the XML markup a bit with \nsed\n to split it into manageable lines.\n\n\n\n```bash\nunzip -p Position-Paper-Final-Version.docx word/document.xml |\nsed -e 's/></>\\n</g' |\ngrep DeCSS\n```"
  },
  {
    "instruction": "Use gzip to compress the files in a directory except for already existing .gz files\n\nI have a directory of logs that I would like to set up a job to compress using \ngzip\n. The issue is I don't want to recompress the logs I've already compressed.\n\n\nI tried using \nls | grep -v gz | gzip\n, but that doesn't seem to work.\n\n\nIs there a way to do this? Basically I want to gzip every file in the directory that does not end in .gz.",
    "input": "",
    "output": "You can just do:\n\n\n\n```bash\ngzip *\n```\n\n\n\ngzip will tell you it skips the files that already have a \n.gz\n  ending.\n\nIf that message gets in the way you can use:\n\n\n\n```bash\ngzip -q *\n```\n\n\n\n\n\nWhat you tried did not work, because \ngzip\n doesn't read the filenames of the files to compress from stdin, for that to work you would have to use:\n\n\n\n```bash\nls | grep -v gz | xargs gzip\n```\n\n\n\nYou will exclude files with the pattern \ngz\n anywhere in the file name, not just at the end.¹ You also have to take note that parsing the output of \nls\n is dangerous when you have file names with spaces, newlines, etc., are involved.\n\n\nA more clean solution, not relying on \ngzip\n to skip files with a \n.gz\n ending is, that also handles non-compressed files in subdirectories:\n\n\n\n```bash\nfind .  -type f ! -name \"*.gz\" -exec gzip {} \\;\n```\n\n\n\n\n\n\n\n¹ \nAs \nizkata\n commented: using \n.gz\n alone to improve this, would not work. You would need to use \ngrep -vF .gz\n or \ngrep -v '\\.gz$'\n. That still leaves the danger of processing \nls\n' output"
  },
  {
    "instruction": "How do I clear Bash&#39;s cache of paths to executables?\n\nWhen I execute a program without specifying the full path to the executable, and Bash must search the directories in \n$PATH\n to find the binary, it seems that Bash remembers the path in some sort of cache. For example, I installed a build of Subversion from source to \n/usr/local\n, then typed \nsvnsync help\n at the Bash prompt. Bash located the binary \n/usr/local/bin/svnsync\n for \"svnsync\" and executed it. Then when I deleted the installation of Subversion in \n/usr/local\n and re-ran \nsvnsync help\n, Bash responds:\n\n\n\n```bash\nbash: /usr/local/bin/svnsync: No such file or directory\n```\n\n\n\nBut, when I start a new instance of Bash, it finds and executes \n/usr/bin/svnsync\n.\n\n\nHow do I clear the cache of paths to executables?",
    "input": "",
    "output": "bash\n does cache the full path to a command.  You can verify that the command you are trying to execute is hashed with the \ntype\n command:\n\n\n\n```bash\n$ type svnsync\nsvnsync is hashed (/usr/local/bin/svnsync)\n```\n\n\n\nTo clear the entire cache:\n\n\n\n```bash\n$ hash -r\n```\n\n\n\nOr just one entry:\n\n\n\n```bash\n$ hash -d svnsync\n```\n\n\n\nFor additional information, consult \nhelp hash\n and \nman bash\n."
  },
  {
    "instruction": "How to grep standard error stream (stderr)?\n\nI am using ffmpeg to get the meta info of an audio clip. But I am unable to grep it.\n\n\n\n```bash\n$ ffmpeg -i 01-Daemon.mp3  |grep -i Duration\n    FFmpeg version SVN-r15261, Copyright (c) 2000-2008 Fabrice Bellard, et al.\n      configuration: --prefix=/usr --bindir=/usr/bin \n      --datadir=/usr/share/ffmpeg --incdir=/usr/include/ffmpeg --libdir=/usr/lib\n      --mandir=/usr/share/man --arch=i386 --extra-cflags=-O2 \n      ...\n```\n\n\n\nI checked, this ffmpeg output is directed to stderr.\n\n\n\n```bash\n$ ffmpeg -i 01-Daemon.mp3 2> /dev/null\n```\n\n\n\nSo I think that grep is unable to read error stream to catch matching lines. How can we enable grep to read error stream?\n\n\nUsing \nnixCraft\n link, I redirected standard error stream to standard output stream, then grep worked.\n\n\n\n```bash\n$ ffmpeg -i 01-Daemon.mp3 2>&1 | grep -i Duration\n  Duration: 01:15:12.33, start: 0.000000, bitrate: 64 kb/s\n```\n\n\n\nBut what if we do not want to redirect stderr to stdout?",
    "input": "",
    "output": "If you're using \nbash\n why not employ anonymous pipes, in essence shorthand for what @phunehehe said:\n\n\n\n```bash\nffmpeg -i 01-Daemon.mp3 2> >(grep -i Duration)\n```\n\n\n\nAnd, as suggested by @tlo, to keep the filtered output in \nstderr\n, use:\n\n\n\n```bash\nffmpeg -i 01-Daemon.mp3 2> >(grep -i Duration >&2)\n```"
  },
  {
    "instruction": "&quot;X11 forwarding request failed&quot; when connecting to github.com\n\nI'm getting a bizarre error message while using git:\n\n\n\n```bash\n$ git clone git@github.com:Itseez/opencv.git\nCloning into 'opencv'\nWarning: Permanently added the RSA host key for IP address '192.30.252.128' to the list of known hosts.\nX11 forwarding request failed on channel 0\n(...)\n```\n\n\n\nI was under the impression that X11 wasn't required for git, so this seemed strange. This clone worked successfully, so this is more of a \"warning\" issue than an \"error\" issue, but it seem unsettling. After all, git shouldn't \nneed\n X11. Any suggestions?",
    "input": "",
    "output": "Note that to disable \nForwardX11\n just for github.com you need something like the following in your \n~/.ssh/config\n\n\n\n```bash\nHost github.com\n    ForwardX11 no\n\nHost *\n    ForwardX11 yes\n```\n\n\n\nThe last two lines assume that in general you /do/ want to forward your X connection. This can cause confusion because the following is WRONG:\n\n\n\n```bash\nForwardX11 yes\n\nHost github.com\n    ForwardX11 no\n```\n\n\n\nWhich is what I had (and caused me no end of confusion). This is because in .ssh/config, the first setting wins, and isn't overwritten by subsequent customizations.\n\n\nHTH, Dan."
  },
  {
    "instruction": "Is there a usable gui front-end to git on Linux?\n\nI'm a former windows user and just started using ubuntu. On windows, we had two great softwares: \nTortoiseSVN\n and \nTortoiseGit\n. Both are so good programs that they allow us to do everything like commit, rollback, merge, view history, browse repos, etc. without knowing a SINGLE cli command.\n\n\nNow on linux, I'm finding it difficult to do memorize git commands for everything. \ngit push\n and \ngit remote add\n is fine. But merging is tedious especially conflict-resolution. In TortoiseGit, it is simply a matter of a few right-clicks!\n\n\nI've found some crap like git-gui, etc. but the features are nothing comparable to TortoiseGit. Why isn't there any fully-fledged TortoiseGit port on linux systems?",
    "input": "",
    "output": "The GIT project maintains a page with all the GUIs available for all platforms both free and commercial. I'd list them all here but it's a pretty extensive list with screenshots and descriptions.\n\n\n\n\nGUI Clients\n\n\n\n\nGIT also comes, typically with 2 GUIs. You can run them as follows:\n\n\n\n```bash\n$ git gui\n```\n\n\n\n             \n\n\nIf you're in a GIT workspace that you've cloned locally you can use \ngitk\n to browse it:\n\n\n\n```bash\n$ gitk\n```\n\n\n\n    \n\n\nNOTE:\n If they aren't installed you can install them, typically, with these package names: \n\n\n\n```bash\n- git-gui\n- gitk\n```\n\n\n\nOther options\n\n\nFrom the GIT page there are these options that are free for Linux.\n\n\n\n\ngit-cola\n\n\n\n\n        \n\n\n\n\nSmartGit\n\n\n\n\n        \n\n\n\n\nGitEye\n\n\n\n\n        \n\n\n\n\ngiggle\n\n\n\n\n        \n\n\n\n\ngitg"
  },
  {
    "instruction": "Make grown extracted tar file small again\n\nI packed and compressed a folder to a .tar.gz archive.\nAfter unpacking it was nearly twice as big.\n\n\n\n```bash\ndu -sh /path/to/old/folder       = 263M\ndu -sh /path/to/extracted/folder = 420M\n```\n\n\n\nI searched a lot and found out that tar is actually causing this issue by adding metadata or doing other weird stuff with it.\n\n\nI made a diff on 2 files inside the folder, as well as a md5sum. There is absolutely no diff and the checksum is the exact same value. Yet, one file is as twice as big as the original one.\n\n\n\n```bash\nroot@server:~# du -sh /path/to/old/folder/subfolder/file.mcapm /path/to/extracted/folder/subfolder/file.mcapm\n1.1M    /path/to/old/folder/subfolder/file.mcapm\n2.4M    /path/to/extracted/folder/subfolder/file.mcapm\nroot@server:~# diff /path/to/old/folder/subfolder/file.mcapm /path/to/extracted/folder/subfolder/file.mcapm\nroot@server:~# \nroot@server:~# md5sum /path/to/old/folder/subfolder/file.mcapm\nroot@server:~# f11787a7dd9dcaa510bb63eeaad3f2ad\nroot@server:~# md5sum /path/to/extracted/folder/subfolder/file.mcapm\nroot@server:~# f11787a7dd9dcaa510bb63eeaad3f2ad\n```\n\n\n\nI am not searching for different methods, but for a way to reduce the size of those files again to their original size.\n\n\nHow can I achieve that?",
    "input": "",
    "output": "[this answer is assuming GNU tar and GNU cp]\n\n\n\n> There is absolutely no diff and the checksum is the exact same value. Yet, one file is as twice as big as the original one.\n> ```bash\n> 1.1M    /path/to/old/folder/subfolder/file.mcapm\n> 2.4M    /path/to/extracted/folder/subfolder/file.mcapm\n> ```\n\n\n\nThat \n.mcapm\n file is probably \nsparse\n. Use the \n-S\n (\n--sparse\n) \ntar\n option when creating the archive.\n\n\nExample:\n\n\n\n```bash\n$ dd if=/dev/null seek=100 of=dummy\n...\n$ mkdir extracted\n\n$ tar -zcf dummy.tgz dummy\n$ tar -C extracted -zxf dummy.tgz\n$ du -sh dummy extracted/dummy\n0       dummy\n52K     extracted/dummy\n\n$ tar -S -zcf dummy.tgz dummy\n$ tar -C extracted -zxf dummy.tgz\n$ du -sh dummy extracted/dummy\n0       dummy\n0       extracted/dummy\n```\n\n\n\nYou can also \"re-sparse\" a file afterwards with \ncp --sparse=always\n:\n\n\n\n```bash\n$ dd if=/dev/zero of=junk count=100\n...\n$ du -sh junk\n52K     junk\n$ cp --sparse=always junk junk.sparse && mv junk.sparse junk\n$ du -sh junk\n0       junk\n```"
  },
  {
    "instruction": "How can I use grep to search multiple unnested directories?\n\nIt may sound like I'm asking the same thing as \nthis question\n, but I have different requirements. This is an example of my filesystem:\n\n\n\n\n/code/\n\n\n\n\ninternal/\n\n\n\n\ndev/\n\n\nmain/\n\n\n\n\npublic/\n\n\n\n\ndev/\n\n\nmain/\n\n\nrelease/\n\n\n\n\ntools/\n\n\n\n\n\n\n/code/internal/dev/\n, \n/code/public/dev/\n and \n/code/tools/\n contain subdirectories for multiple projects. I work almost exclusively in the dev branches of \n/code/internal/\n and \n/code/public/\n, and often I want to search for a text string in those directories along with \n/code/tools/\n (which has no branches). In these instances I have to do three separate commands:\n\n\n\n```bash\n$ grep -r \"some string\" /code/internal/dev/\n$ grep -r \"some string\" /code/public/dev/\n$ grep -r \"some string\" /code/tools/\n```\n\n\n\nI'd like to know if there's a single command to do this. If not, I would most likely need to write a simple bash script.",
    "input": "",
    "output": "You can concatenate several paths for grep to look for:\n\n\n\n```bash\ngrep -r \"some string\" /code/internal/dev/ /code/public/dev/ /code/tools/\n```"
  },
  {
    "instruction": "How to untar safely, without polluting the current directory in case of a tarbomb?\n\nRespectable projects release tar archives that contain a single directory, for instance \nzyrgus-3.18.tar.gz\n contains a \nzyrgus-3.18\n folder which in turn contains \nsrc\n, \nbuild\n, \ndist\n, etc.\n\n\nBut some punk projects put everything at the root :'-( This results in a \ntotal mess\n when unarchiving. Creating a folder manually every time is a pain, and unnecessary most of the time.\n\n\n\n\nIs there a super-fast way to tell whether a .tar or .tar.gz file contains more than a single directory at its root? Even for a big archive.\n\n\nOr even better, is there a tool that in such cases would create a directory (name of the archive without the extension) and put everything inside?",
    "input": "",
    "output": "patool\n handles different kinds of archives and creates a subdirectory in case the archive contains multiple files to prevent cluttering the working directory with the extracted files.\n\n\nExtract archive\n\n\n\n```bash\npatool extract archive.tar\n```\n\n\n\nTo obtain a list of the supported formats, use \npatool formats\n."
  },
  {
    "instruction": "How do I change the extension of multiple files?\n\nI would like to change a file extension from \n*.txt\n to \n*.text\n. I tried using the \nbasename\n command, but I'm having trouble changing more than one file.\n\n\nHere's my code:\n\n\n\n```bash\nfiles=`ls -1 *.txt`\n\nfor x in $files\ndo\n    mv $x \"`basename $files .txt`.text\"\ndone\n```\n\n\n\nI'm getting this error:\n\n\n\n> basename: too many arguments Try basename --help' for more information",
    "input": "",
    "output": "Straight from \nGreg's Wiki\n:\n\n\n\n```bash\n# Rename all *.txt to *.text\nfor file in *.txt; do\n    mv -- \"$file\" \"${file%.txt}.text\"\ndone\n```\n\n\n\n*.txt\n is \na globbing pattern\n, using \n*\n as a wildcard to match any string. \n*.txt\n matches all filenames ending with '.txt'.\n\n\n--\n \nmarks the end of the option list\n. This avoids issues with filenames starting with hyphens.\n\n\n${file%.txt}\n is \na parameter expansion\n, replaced by the value of the \nfile\n variable with \n.txt\n removed from the end.\n\n\nAlso see the entry on why you \nshouldn't parse \nls\n.\n\n\nIf you have to use \nbasename\n, your syntax would be:\n\n\n\n```bash\nfor file in *.txt; do\n    mv -- \"$file\" \"$(basename -- \"$file\" .txt).text\"\ndone\n```"
  },
  {
    "instruction": "gunzip a folder with many files\n\nI have a folder with 36,348 files gz files. I want to unzip all of them.\n\n\nRunning: \n\n\n\n```bash\ngunzip ./*\n```\n\n\n\nresults in \n\n\n\n```bash\n-bash: /usr/bin/gunzip: Argument list too long\n```\n\n\n\nWhat's the easiest way to get around this?",
    "input": "",
    "output": "Try:\n\n\n\n```bash\nfind . -type f -exec gunzip {} +\n```\n\n\n\nThis assumes that current directory only contains files that you want to unzip."
  },
  {
    "instruction": "What does &quot;--&quot; mean in Linux/Unix command line?\n\n> Possible Duplicate:\n> What does “--” (double-dash) mean?\n\n\n\ngit diff [options] [<commit>] [--] [<path>…]\n\n\nIn here, how should I understand what [--] means? And when should I use it.",
    "input": "",
    "output": "The \n--\n is commonly used in command to indicate the end of options. This is useful if your filename begins with a \"-\" or your input is unknown. Here is an example of its use:\n\n\ngit diff --stat -- --file1 --file2\n\n\n--file1\n is treated as a filename rather than another option."
  },
  {
    "instruction": "What is the difference between grep -e and grep -E option?\n\nI am trying to understand the difference between \ngrep -e\n and \ngrep -E\n. Now from \ngrep manpage\n I got:\n\n\n\n> -E, --extended-regexp\n> Interpret PATTERN as an extended regular expression (see below).\n> -e PATTERN, --regexp=PATTERN\n> Use PATTERN as the pattern; useful to protect patterns beginning with -\n\n\n\nThe above explanation does not make sense for me.\n\n\nSo, can someone explain it to me using \nexamples\n what is the difference between the two  and when to use which option.\n\n\nPS: Version: grep (GNU grep) 2.10",
    "input": "",
    "output": "-e\n is strictly the flag for indicating the pattern you want to match against. \n-E\n controls whether you need to escape certain special characters.\n\n\nman grep\n explains \n-E\n it a bit more:\n\n\n\n```bash\nBasic vs Extended Regular Expressions\nIn basic regular expressions the meta-characters ?, +, {, |, (, and ) lose their \nspecial meaning; instead use the backslashed versions \\?, \\+, \\{, \\|, \\(, and \\).\n\nTraditional  egrep  did  not  support  the  {  meta-character, and some egrep \nimplementations support \\{ instead, so portable scripts should avoid { in grep -E\npatterns and should use [{] to match a literal {.\n\nGNU grep -E attempts to support traditional usage by assuming that { is not \nspecial if it would be the start of an invalid interval specification. \nFor example, the command grep -E '{1' searches for the two-character string {1 \ninstead of reporting a syntax error in the regular expression.  POSIX.2 allows \nthis behavior as an extension, but portable scripts should avoid it.\n```"
  },
  {
    "instruction": "What is the difference between the Bash operators [[ vs [ vs ( vs ((?\n\nI am a little bit confused on what do these operators do differently when used in bash (brackets, double brackets, parenthesis and double parenthesis).\n\n\n\n```bash\n[[ , [ , ( , ((\n```\n\n\n\nI have seen people use them on \nif\n statements like this:\n\n\n\n```bash\nif [[ condition ]]\n\nif [ condition ]\n\nif ((condition))\n\nif (condition)\n```",
    "input": "",
    "output": "In Bourne-like shells, an \nif\n statement typically looks like\n\n\n\n```bash\nif\n   command-list1\nthen\n   command-list2\nelse\n   command-list3\nfi\n```\n\n\n\nThe \nthen\n clause is executed if the exit code of the \ncommand-list1\n list of commands is zero.  If the exit code is nonzero, then the \nelse\n clause is executed.  \ncommand-list1\n can be\nsimple or complex.  It can, for example, be a sequence of one or more pipelines separated by one of the operators \n;\n, \n&\n, \n&&\n, \n||\n or newline.  The \nif\n conditions shown below are just special cases of \ncommand-list1\n:\n\n\n\n\nif [ condition ]\n\n\n[\n is another name for the traditional \ntest\n command.  \n[\n / \ntest\n is a standard POSIX utility. All POSIX shells have it builtin (though that's not required by POSIX²).  The \ntest\n command sets an exit code and the \nif\n statement acts accordingly.  Typical tests are whether a file exists or one number is equal to another.\n\n\n\n\nif [[ condition ]]\n\n\nThis is a new upgraded variation on \ntest\n¹ from \nksh\n that \nbash\n, \nzsh\n, \nyash\n, \nbusybox sh\n also support.  This \n[[ ... ]]\n construct also sets an exit code and the \nif\n statement acts accordingly.  Among its extended features, it can test whether a string matches a wildcard pattern (not in \nbusybox sh\n).\n\n\n\n\nif ((condition))\n\n\nAnother \nksh\n extension that \nbash\n and \nzsh\n also support. This performs arithmetic.  As the result of the arithmetic, an exit code is set and  the \nif\n statement acts accordingly.  It returns an exit code of zero (true) if the result of the arithmetic calculation is nonzero.  Like \n[[...]]\n, this form is not POSIX and therefore not portable.\n\n\n\n\nif (command)\n\n\nThis runs command in a subshell.  When command completes, it sets an exit code  and  the \nif\n statement acts accordingly.\n\n\nA typical reason for using a subshell like this is to limit side-effects of \ncommand\n if \ncommand\n required variable assignments or other changes to the shell's environment.  Such changes do not remain after the subshell completes.\n\n\n\n\nif command\n\n\ncommand is executed and the \nif\n statement acts according to its exit code.\n\n\n\n\n\n\nNote that \n[ ... ]\n and \n[[ ... ]]\n require whitespace around them, while \n(...)\n and \n((...))\n do not.\n\n\n\n\n¹ though not really a command but a special shell construct with its own separate syntax from that of normal command, and varying significantly between shell implementations\n\n\n² POSIX does require that there be a standalone \ntest\n and \n[\n utilities on the system however, though in the case of \n[\n, several Linux distributions have been known to be missing it."
  },
  {
    "instruction": "grep and escaping a dollar sign\n\nI want to know which files have the string \n$Id$\n.\n\n\n\n```bash\ngrep \\$Id\\$  my_dir/mylist_of_files\n```\n\n\n\nreturns 0 occurrences.\n\n\nI discovered that I have to use\n\n\ngrep \\$Id$ my_dir/mylist_of_files\n\n\nThen I see that the \n$Id\n is colored in the output, i.e. it has been matched.\n\n\nHow could I match the second \n$\n and why doesn't \n\\$Id\\$\n work.\n\n\nIt doesn't matter if the second \n$\n is the last character or not.\n\n\nI use \ngrep\n 2.9.\n\n\n\n\nBefore posting my question, I used google...\n\n\nI found an answer\n\n\n\n> To search for a $ (dollar sign) in the file named test2, enter:\n> grep \\\\$ test2\n> The \\\\ (double backslash) characters are necessary in order\n> to force the shell to pass a \\$ (single backslash, dollar sign) to the\n> grep command. The \\ (single backslash) character tells the grep\n> command to treat the following character (in this example the $) as a\n> literal character rather than an expression character. Use the fgrep\n> command to avoid the necessity of using escape characters such as the\n> backslash.\n\n\n\nbut I don't understand why \ngrep \\$Id\n works and why \ngrep \\\\$Id\\\\$\n doesn't.\n\n\nI'm a little bit confused...",
    "input": "",
    "output": "There's 2 separate issues here.\n\n\n\n\ngrep\n uses \nBasic Regular Expressions\n (BRE), and \n$\n is a special character in BRE's only at the end of an expression.  The consequence of this is that the 2 instances of \n$\n in \n$Id$\n are not equal.  The first one is a normal character and the second is an anchor that matches the end of the line.  To make the second \n$\n match a literal \n$\n you'll have to backslash escape it, i.e. \n$Id\\$\n.  Escaping the first \n$\n also works: \n\\$Id\\$\n, and I prefer this since it looks more consistent.¹\n\n\n\n\nThere are two completely unrelated escaping/quoting mechanisms at work here: shell quoting and regex backslash quoting.  The problem is many characters that regular expressions use are special to the shell as well, and on top of that the regex escape character, the backslash, is also a shell quoting character.  This is why you often see messes involving double backslashes, but I do not recommend using backslashes for shell quoting regular expressions because it is not very readable.\n\n\nInstead, the simplest way to do this is to first put your entire regex inside single quotes as in \n'regex'\n.  The single quote is the strongest form of quoting the shell has, so as long as your regex does not contain single quotes, you no longer have to worry about shell quoting and can focus on pure BRE syntax.\n\n\n\n\n\n\nSo, applying this back to your original example, let's throw the correct regex (\n\\$Id\\$\n) inside single quotes.  The following should do what you want:\n\n\n\n```bash\ngrep '\\$Id\\$' my_dir/my_file\n```\n\n\n\nThe reason \n\\$Id\\$\n does not work is because after shell quote removal (the more correct way of saying  shell quoting) is applied, the regex that \ngrep\n sees is \n$Id$\n.  As explained in (1.), this regex matches a literal \n$Id\n only at the end of a line because the first \n$\n is literal while the second is a special anchor character.\n\n\n¹ Note also that if you ever switch to Extended Regular Expressions (ERE), e.g. if you decided to use \negrep\n (or \ngrep -E\n), the \n$\n character is always special.  In ERE's \n$Id$\n would never match anything because you can't have characters \nafter\n the end of a line, so \n\\$Id\\$\n would be the only way to go."
  },
  {
    "instruction": "How can I count the number of lines of a file with common tools?\n\nI am redirecting \ngrep\n results to a file, and then using \ncat\n to show its contents on the screen. I want to know how many lines of results I have in my results file and then add it to some counter.\n\n\nWhat will be the best way? Any relevant flag to \ngrep\n or \ncat\n?",
    "input": "",
    "output": "If you have already collected the \ngrep\n output in a file, you could output a numbered list with:\n\n\n\n```bash\ncat -n myfile\n```\n\n\n\nIf you only want the number of lines, simply do:\n\n\n\n```bash\nwc -l myfile\n```\n\n\n\nThere is absolutely no reason to do:\n\n\n\n```bash\ncat myfile | wc -l\n```\n\n\n\n...as this needlessly does I/O (the \ncat\n) that \nwc\n has to repeat.  Besides, you have two processes where one suffices.\n\n\nIf you want to \ngrep\n to your terminal and print a count of the matches at the end, you can do:\n\n\n\n```bash\ngrep whatever myfile | tee /dev/tty | wc -l\n```\n\n\n\n\n\nNote: \n/dev/tty\n is the controlling terminal. From the \ntty(4)\n man page\n:\n\n\n\n> The file /dev/tty is a character file with major number 5 and minor number 0, usually of mode 0666 and owner.group root.tty. It is a synonym for the controlling terminal of a process, if any.\n> In addition to the ioctl(2) requests supported by the device that tty refers to, the ioctl(2) request TIOCNOTTY is supported."
  },
  {
    "instruction": "How to create tar archive in a different directory?\n\nI want to create a tar archive in a different directory rather than the current directory.\n\n\nI tried this command:\n\n\n\n```bash\ntar czf file.tar.gz file1 -C /var/www/\n```\n\n\n\nbut it creates the archive in the current directory. Why?",
    "input": "",
    "output": "The easy way, if you don't particularly \nneed\n to use \n-C\n to tell \ntar\n to change to some other directory, is to simply specify the full path to the archive on the command line. Then you can be in whatever directory you prefer to create the directory structure that you want inside the archive.\n\n\nThe following will create the archive \n/var/www/file.tar.gz\n and put \nfile1\n from the current directory (whatever that happens to be) in it, with no in-archive path information.\n\n\n\n```bash\ntar czf /var/www/file.tar.gz file1\n```\n\n\n\nThe path (to either the archive, the constituent files, or both) can of course also be relative. If \nfile1\n is in \n/tmp\n, you are in \n/var/spool\n and want to create the archive in \n/var/www\n, you could use something like:\n\n\n\n```bash\ntar czf ../www/file1.tar.gz /tmp/file1\n```\n\n\n\nThere's a million variations on the theme, but this should get you started. Add the \nv\n flag if you want to see what \ntar\n actually does."
  },
  {
    "instruction": "Run a command that is shadowed by an alias\n\nLet's say I have the following alias in bash - \nalias ls='ls --color=auto'\n - and I want to call ordinary \nls\n without options. Is the only way to do that is to unalias, do the command and then alias again? Or there is some nifty trick or workaround?",
    "input": "",
    "output": "You can also prefix a back slash to disable the alias: \n\\ls\n\n\nEdit: Other ways of doing the same include:\n\n\nUse \"command\": \ncommand ls\n as per \nMikel\n.\n\n\nUse the full path: \n/bin/ls\n as per \nuther\n.\n\n\nQuote the command: \n\"ls\"\n or \n'ls'\n as per Mikel comment.\n\n\nYou can remove the alias temporarily for that terminal session with \nunalias command_name\n."
  },
  {
    "instruction": "How can I grep for this or that (2 things) in a file?\n\nI have a file that has \"then\"'s and \"there\"'s.\n\n\nI can \n\n\n\n```bash\n$ grep \"then \" x.x\nx and then some\nx and then some\nx and then some\nx and then some\n```\n\n\n\nand I can\n\n\n\n```bash\n$ grep \"there \" x.x\nIf there is no blob none some will be created\n```\n\n\n\nHow can I search for both in one operation?\nI tried\n\n\n\n```bash\n$ grep (then|there) x.x\n```\n\n\n\n-bash: syntax error near unexpected token `('\n\n\nand\n\n\n\n```bash\ngrep \"(then|there)\" x.x\ndurrantm.../code\n# (Nothing)\n```",
    "input": "",
    "output": "You need to put the expression in quotation marks. The error you are receiving is a result of bash interpretting the \n(\n as a special character.\n\n\nAlso, you need to tell grep to use extended regular expressions.\n\n\n\n```bash\n$ grep -E '(then|there)' x.x\n```\n\n\n\nWithout extended regular expressions, you have to escape the \n|\n, \n(\n, and \n)\n. Note that we use single quotation marks here. Bash treats backslashes within double quotation marks specially.\n\n\n\n```bash\n$ grep '\\(then\\|there\\)' x.x\n```\n\n\n\nThe grouping isn't necessary in this case.\n\n\n\n```bash\n$ grep 'then\\|there' x.x\n```\n\n\n\nIt would be necessary for something like this:\n\n\n\n```bash\n$ grep 'the\\(n\\|re\\)' x.x\n```"
  },
  {
    "instruction": "How can I suppress output from grep, so that it only returns the exit status?\n\nI have the \ngrep\n command. I'm searching for a keyword from a file, but I don't want to display the match. I just want to know the exit status of the \ngrep\n.",
    "input": "",
    "output": "Any \nPOSIX compliant version of \ngrep\n has the switch \n-q\n for quiet:\n\n\n\n```bash\n-q\n     Quiet. Nothing shall be written to the standard output, regardless\n     of matching lines. Exit with zero status if an input line is selected.\n```\n\n\n\nIn GNU grep (and possibly others) you can use long-option synonyms as well:\n\n\n\n```bash\n-q, --quiet, --silent     suppress all normal output\n```\n\n\n\nExample\n\n\nString exists:\n\n\n\n```bash\n$ echo \"here\" | grep -q \"here\"\n$ echo $?\n0\n```\n\n\n\nString doesn't exist:\n\n\n\n```bash\n$ echo \"here\" | grep -q \"not here\"\n$ echo $?\n1\n```"
  },
  {
    "instruction": "Is it possible to make zcat output text even if it&#39;s uncompressed?\n\nThe problem is I have some database dumps which are either compressed or in plain text. There is no difference in file extension etc. Using \nzcat\n on uncompressed files produces an error instead of the output.\n\n\nIs there maybe another \ncat\n sort of tool that is smart enough to detect what type of input it gets?",
    "input": "",
    "output": "Just add the \n-f\n option.\n\n\n\n```bash\n$ echo foo | tee file | gzip > file.gz\n$ zcat file file.gz\ngzip: file: not in gzip format\nfoo\n$ zcat -f file file.gz\nfoo\nfoo\n```\n\n\n\n(use \ngzip -dcf\n instead of \nzcat -f\n if your \nzcat\n is not the GNU (or GNU-emulated like in modern BSDs) one and only knows about \n.Z\n files)."
  },
  {
    "instruction": "gzip: unexpected end of file with - how to read file anyway\n\nI have a job on a batch system that runs extremely long and produces tons of output. So much actually that I have to pipe the standard output through gzip to keep the batch node from filling its work area and subsequently crashing.\n\n\n\n```bash\nlongscript | gzip -9 > log.gz\n```\n\n\n\nNow, I would like to investigate the output of the job while it is still running.\nSo I do this:\n\n\n\n```bash\ngunzip log.gz\n```\n\n\n\nThis runs very long, as it is huge file (several GB). I can see the output file being created while it is running and can look at it while it is being built.\n\n\n\n```bash\ntail log\n> some-line-of-the-log-file\ntail log\n> some-other-line-of-the-log-file\n```\n\n\n\nHowever, ultimately, gzip encounters the end of the gzipped file. Since the job is still running and gzip is still writing the file, there is no proper footer yet, so this happens:\n\n\n\n```bash\ngzip: log.gz: unexpected end of file\n```\n\n\n\nAfter this, the extracted log file is deleted, as gzip thinks that the corrupted extracted data is of no use to me. I, however, disagree - even if the last couple of lines are scrambled, the output is still highly interesting to me.\n\n\nHow can I convince gzip to let me keep the \"corrupted\" file?",
    "input": "",
    "output": "Apart from the very end of the file, you will be able to see the uncompressed data with \nzcat\n (or \ngzip -dc\n, or \ngunzip -c\n):\n\n\n\n```bash\nzcat log.gz | tail\n```\n\n\n\nor\n\n\n\n```bash\nzcat log.gz | less\n```\n\n\n\nor\n\n\n\n```bash\nzless log.gz\n```\n\n\n\ngzip\n will do buffering for obvious reasons (it needs to compress the data in chunks), so even though the program may have outputted some data, that data may not yet be in the \nlog.gz\n file.\n\n\nYou may also store the uncompressed log with\n\n\n\n```bash\nzcat log.gz > log\n```\n\n\n\n... but that would be silly since there's obviously a reason why you compress the output in the first place."
  },
  {
    "instruction": "Is there a way to convert a zip to a tar without extracting it to the filesystem?\n\nIs there a way to convert a \nzip\n archive to a \ntar\n archive without extracting to a temporary directory first? (and without writing my own implementation of \ntar\n or \nunzip\n)",
    "input": "",
    "output": "This is now available as installable command from PyPI, see the end of this post.\n\n\n\n\nI don't know of any \"standard\" utility that does so, but when I needed this functionality I wrote the following Python script to go from ZIP to Bzip2 compressed tar archives without extracting anything to disk first:\n\n\n\n```bash\n#! /usr/bin/env python\n    \n\"\"\"zip2tar \"\"\"\n\nimport sys\nimport os\nfrom zipfile import ZipFile\nimport tarfile\nimport time\n\ndef main(ifn, ofn):\n    with ZipFile(ifn) as zipf:\n        with tarfile.open(ofn, 'w:bz2') as tarf:\n            for zip_info in zipf.infolist():\n                #print zip_info.filename, zip_info.file_size\n                tar_info = tarfile.TarInfo(name=zip_info.filename)\n                tar_info.size = zip_info.file_size\n                tar_info.mtime = time.mktime(tuple(zip_info.date_time) +\n                                         (-1, -1, -1))\n                tarf.addfile(\n                    tarinfo=tar_info,\n                    fileobj=zipf.open(zip_info.filename)\n                )\n\ninput_file_name = sys.argv[1]\noutput_file_name = os.path.splitext(input_file_name)[0] + '.tar.bz2'\n\nmain(input_file_name, output_file_name)\n```\n\n\n\nJust save it to \nzip2tar\n and make it executable or save it to \nzip2tar.py\n and  run \npython zip2tar.py\n. Provide the ZIP filename as an argument to the script, the output filename for \nxyz.zip\n will be \nxyz.tar.bz2\n.\n\n\nThe Bzip2 compressed output is normally much smaller than the zip file because the latter doesn't use compression patterns over multiple files, but there is also less chance of recovering later file if something in the Bzip2 file is wrong.\n\n\nIf you don't want the output compressed, remove \n:bz2\n and \n.bz2\n from the code.\n\n\n\n\nIf you have \npip\n installed in a python3 environment, you can do:\n\n\n\n```bash\npip3 install ruamel.zip2tar\n```\n\n\n\nto get a \nzip2tar\n commandline utility doing the above (disclaimer: I am the author of that package)."
  },
  {
    "instruction": "Why can&#39;t tar extract .zip files?\n\nI tried a majority of the formats (gzip, etc.) to extract a zip file with \ntar\n, and when I became frustrated enough to Google for it, I found no way to extract a zip file with \ntar\n and only recommendations to use \nzip\n or \nunzip\n. As a matter of fact, my Linux system doesn't even have a \nzip\n utility, but only \nunzip\n (leaving me to wonder why this is the main recommended option). Of course \nunzip\n worked, solving my problem, but why can't \ntar\n extract zip files? Perhaps I should instead be asking, what is the difference between zip and the compression methods supported by \ntar\n?",
    "input": "",
    "output": "The UNIX philosophy is to have small tools. One tool is doing exactly one thing, but this especially well.\n\n\nThe \ntar\n tool is just combining several files into a single file without any compression.\n\n\nThe \ngzip\n tool is just compressing a single file.\n\n\nIf you want to have both, you just combine both tools resulting in a \n.tar.gz\n file.\n\n\n\n\nThe \nzip\n tool is a completely different thing. It takes a bunch of files and combines them into a single compressed file. With totally different algorithms.\n\n\n\n\nIf you want one tool to rule them all use \natool\n. It will support a \nwhole bunch\n of different formats simply by detecting the format and calling the correct tool."
  },
  {
    "instruction": "How to show lines after each grep match until other specific match?\n\nI know that by using the \n\"-A NUM\"\n switch I can print specific number of trailing lines after each match. I am just wondering if it's possible to print trailing lines until a specific word is found after each match. e.g. When I search for \"Word A\" I want to see the line containing \"Word A\" and also the lines after it until the one containing \"Word D\".\n\n\ncontext:\n\n\n\n```bash\nWord A\nWord B\nWord C\nWord D\nWord E\nWord F\n```\n\n\n\ncommand:\n\n\n\n```bash\ngrep -A10 'Word A'\n```\n\n\n\nI need this output:\n\n\n\n```bash\nWord A\nWord B\nWord C\nWord D\n```",
    "input": "",
    "output": "It seems that you want to print lines between '\nWord A\n' and '\nWord D\n' (inclusive). I suggest you to use \nsed\n instead of \ngrep\n. It lets you to edit a range of input stream which starts and ends with patterns you want. You should just tell \nsed\n to print all lines in range and no other lines:\n\n\n\n```bash\nsed -n -e '/Word A/,/Word D/ p' file\n```"
  },
  {
    "instruction": "How to use multi-threading for creating and extracting tar.xz\n\nI use\n\n\n\n```bash\ntar -cJvf resultfile.tar.xz files_to_compress\n```\n\n\n\nto create \ntar.xz\n and\n\n\n\n```bash\ntar -xzvf resultfile.tar.xz\n```\n\n\n\nto extract the archive in current directory. How to use multi threading in both cases?  I don't want to install any utilities.",
    "input": "",
    "output": "```bash\ntar -c -I 'xz -9 -T0' -f archive.tar.xz [list of files and folders]\n```\n\n\n\nThis compresses a list of files and directories into an \n.tar.xz\n archive. It does so by specifying the arguments to be passed to the \nxz\n subprocess, which compresses the tar archive.\n\n\nThis is done using the \n-I\n argument to tar, which tells \ntar\n what program to use to compress the tar archive, and what arguments to pass to it. The \n-9\n tells \nxz\n to use maximum compression. The \n-T0\n tells \nxz\n to use as many threads as you have CPUs. Note that if you are on MacOS or a BSD distro, the \n-I\n option is available only on GNU tar, not on BSD tar. For MacOS users, this can be resolved by installing \ngnu-tar\n through Homebrew and using the \ngtar\n command instead of \ntar\n.\n\n\n\n\nAn update from January, 2024:\n\n\nEven when using the multithreading option, \nxz\n barely scales beyond two threads, besides its compression/decompression performance is relatively low.\n\n\nI highly recommend using \nZSTD\n instead. The command will be:\n\n\n\n```bash\ntar -c -I 'zstd -22 --ultra --long -T0' -f archive.tar.xz [list of files and folders]\n```\n\n\n\nCaveats:\n\n\n\n\nThis commands needs a lot of RAM, at the very least 5GB. You may want to reduce the compression level, or remove \nultra/long\n options to decrease RAM consumption.\n\n\nThreading might not be used if you don't have enough source data (less than 1GB). If you still want to use threading for a small amount of data, decrease the compression level from 22 to say 20."
  },
  {
    "instruction": "adding SSL certificate for Github only (not all certificates from ca-certificates package)\n\nI get the following error when accessing Github over HTTPS:\n\n\n\n```bash\nerror: server certificate verification failed. \nCAfile: /etc/ssl/certs/ca-certificates.crt CRLfile: none\n```\n\n\n\nThis is because I don't have any certificates in \n/etc/ssl/certs/\n. I know how to fix this problem. I can install the package \nca-certificates\n from Debian repository. The problem is, however, that this will install all certificates (thousands) which I don't necessarily want to accept/trust.\n\n\nHow can I install certificate for Github only?\n\n\na Subproblem/Subquestion\n\n\nOn another machine, where the package \nca-certificates\n is already installed and git works, I have noticed that some certificates in \n/etc/ssl/certs/\n are one-certificate-per-file and other are many-certificates-in-one-file. The particular file containing Github certificate, \n/etc/ssl/certs/ca-certificates.crt\n contains over 150 other certificates:\n\n\n\n```bash\n$ grep 'BEGIN CERTIFICATE' /etc/ssl/certs/ca-certificates.crt | wc -l\n159\n```\n\n\n\nHow can I find which one out of these 159 certificate is the one I need? (other than brute force - slicing the file in halves and checking both halves, repeating \nwhile n > 1\n).",
    "input": "",
    "output": "In order to access your Github you need to do it via ssh. So you need to add your ssh public key to github. After that you are able to access github via ssh i.e.:\n\n\n\n```bash\ngit init git@github.com:yourname/yourrepo.git\n```\n\n\n\nSee also: \nGithub: generating ssh keys\n, \nWikiHow\n\n\n[Edit #1]\n\n\nwithout certificate checks:\n\n\n\n```bash\nGIT_SSL_NO_VERIFY=true git clone https://github.com/p/repo.git\n```\n\n\n\nor authenticated\n\n\n\n```bash\nGIT_SSL_NO_VERIFY=true git clone https://user@pass:github.com/p/repo.git\n```\n\n\n\nFor me it is still not clear what are you asking for, because you know that installing ca-certificates will fix the problem.\n\n\n[Edit #2]\n\n\nOk, the other question was \n\n\n\n> how to have only the certificate which is needed to access github.com via https\n\n\n\n\n\nOpen your browser and navigate to \nhttps://github.com/\n.\nKlick on the green name on the left from \nhttps://\n and klick on\n\nCertificates\n. On the \nDetails\n tab, you'll see the \ncertificate chain, which is:\n\n\n\n```bash\nDigiCert ...\n  DigiCert ...\n   github.com ...\n```\n\n\n\nExport each of the DigiCert certicates to a file.\n\n\ncopy the files to \n/etc/ssl/certs/\n\n\nrun \nc_rehash\n which cat all certificates to \nca-certificates.crt\n\n\nyou are done.\n\n\n\n\nAs I said, I am not a friend of such actions because github can change the CA's anytime, \nso it will always result in additional work."
  }
]